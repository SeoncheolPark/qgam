% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tuneLearn.R
\name{tuneLearn}
\alias{tuneLearn}
\title{Tuning the learning rate for Gibbs posterior}
\usage{
tuneLearn(form, data, lsig, qu, err = 0.01, multicore = !is.null(cluster),
  cluster = NULL, ncores = detectCores() - 1, paropts = list(),
  control = list(), controlGam = list())
}
\arguments{
\item{form}{A GAM formula, or a list of formulae. See ?mgcv::gam details.}

\item{data}{A data frame or list containing the model response variable and covariates required by the formula.
By default the variables are taken from environment(formula): typically the environment from which gam is called.}

\item{lsig}{A vector of value of the log learning rate (log(sigma)) over which the calibration loss function is evaluated.}

\item{qu}{The quantile of interest. Should be in (0, 1).}

\item{err}{An upper bound on the error of the estimated quantile curve. Should be in (0, 1). See XXX for details.}

\item{multicore}{If TRUE the calibration will happen in parallel.}

\item{cluster}{An object of class \code{c("SOCKcluster", "cluster")}. This allowes the user to pass her own cluster,
which will be used if \code{multicore == TRUE}. The user has to remember to stop the cluster.}

\item{ncores}{Number of cores used. Relevant if \code{multicore == TRUE}.}

\item{paropts}{a list of additional options passed into the foreach function when parallel computation is enabled. 
This is important if (for example) your code relies on external data or packages: 
use the .export and .packages arguments to supply them so that all cluster nodes 
have the correct environment set up for computing.}

\item{control}{A list of control parameters for \code{tuneLearn} with entries: \itemize{
                  \item{\code{K} = number of boostrap datasets used for calibration. By default \code{K=50}.}
                  \item{\code{b} = offset parameter used by the mgcv::gauslss. By default \code{b=0}.}
                  \item{\code{verbose} = if TRUE some more details are given. By default \code{verbose=FALSE}.}
                  \item{\code{progress} = argument passed to plyr::llply. By default \code{progress="text"} so that progress
                                          is reported. Set it to \code{"none"} to avoid it.}
}}

\item{controlGam}{A list of control parameters to be passed to the internal \code{mgcv::gam} calls. 
See the \code{control} argument in \code{?mgcv::gam}.}
}
\value{
A vector containing the value of the calibration loss function corresponding to each value of log(sigma).
}
\description{
The learning rate (sigma) of the Gibbs posterior is tuned using a calibration approach,
             based on boostrapping. Here the calibration loss function is evaluated on a grid of values
             provided by the user.
}
\examples{
library(qgam); library(MASS)

# Calibrate learning rate on a grid
set.seed(41444)
sigSeq <- seq(1.5, 5, length.out = 10)
closs <- tuneLearn(form = accel~s(times,k=20,bs="ad"), 
                   data = mcycle, 
                   err = 0.01, 
                   lsig = sigSeq, 
                   qu = 0.5)

plot(sigSeq, closs, type = "b", ylab = "Calibration Loss", xlab = "log(sigma)")

# Pick best log-sigma
best <- sigSeq[ which.min(closs) ]
abline(v = best, lty = 2)

# Fit using the best sigma
fit <- qgam(accel~s(times,k=20,bs="ad"), data = mcycle, qu = 0.5, err = 0.01, lsig = best)
summary(fit)

pred <- predict(fit, se=TRUE)
plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", 
     ylim = c(-150, 80))
lines(mcycle$times, pred$fit, lwd = 1)
lines(mcycle$times, pred$fit + 2*pred$se.fit, lwd = 1, col = 2)
lines(mcycle$times, pred$fit - 2*pred$se.fit, lwd = 1, col = 2)                        
}
\author{
Matteo Fasiolo <matteo.fasiolo@gmail.com>.
}

